df = spark.createDataFrame(
#     [
#         (1, "8/1/2024, 5:16:33 PM","8/1/2024, 5:05:48 PM"),  # create your data here, be consistent in the types.
#         (2,"8/1/2024, 5:04:50 PM","8/1/2024, 5:05:29 PM"),
#         (3,"8/1/2024, 5:04:49 PM","8/1/2024, 5:05:58 PM")
#     ],
#     ["id", "start_date","end_date"]  # add your column names here
# )

df = df.withColumn("Run_Start",to_timestamp('start_date', format = 'MM/dd/yyyy, hh:mm:ss a').cast('timestamp'))\
  .withColumn("Run_End",to_timestamp('end_date', format = 'MM/dd/yyyy, hh:mm:ss a').cast('timestamp'))\
      .withColumn('duration_minutes', round((col("Run_End").cast("long") - col('Run_Start').cast("long"))/60,2))

### final output
id	start_date	          end_date	            Run_Start	                     Run_End	                    duration_minutes
1	  8/1/2024, 5:16:33 PM	8/1/2024, 5:05:48 PM	2024-08-01T17:16:33.000+00:00	2024-08-01T17:05:48.000+00:00	-10.75
2  	8/1/2024, 5:04:50 PM	8/1/2024, 5:05:29 PM	2024-08-01T17:04:50.000+00:00	2024-08-01T17:05:29.000+00:00	0.65
3  	8/1/2024, 5:04:49 PM	8/1/2024, 5:05:58 PM	2024-08-01T17:04:49.000+00:00	2024-08-01T17:05:58.000+00:00	1.15
